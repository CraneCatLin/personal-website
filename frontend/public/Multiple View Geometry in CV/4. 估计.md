## 直接线性变换DLT  
  
此处方法在后续有多处类似应用  
  
#### 基本内容  
  
以二维平面射影变 换为例  
对线性变换$x_i'=Hx_i$  
有$x_i' \times Hx_i=0$  
记H的第i行为$H^{jT}$  
则有  
  
$$  
x_i' \times H x_i =   
\begin{pmatrix}  
y_i' h^{3T} x_i - w_i' h^{2T} x_i \\  
w_i' h^{1T} x_i - x_i' h^{3T} x_i \\  
x_i' h^{2T} x_i - y_i' h^{1T} x_i  
\end{pmatrix}  
=   
\begin{pmatrix}  
y_i'x_i^T h^{3}  - w_i'x_i^T h^{2}\\  
w_i'x_i^T h^{1}- x_i'x_i^T h^{3}  \\  
x_i'x_i^T h^{2} - y_i'x_i^T h^{1}  
\end{pmatrix}  
$$  
  
即有3\*9方程组  
  
$$  
A_i h=  
\begin{bmatrix}  
0^T & -w_i' x_i^T & y_i' x_i^T \\  
w_i' x_i^T & 0^T & -x_i' x_i^T \\  
-y_i' x_i^T & x_i' x_i^T & 0^T  
\end{bmatrix}  
\begin{pmatrix}  
h^1 \\  
h^2 \\  
h^3  
\end{pmatrix}  
= 0  
$$  
  
$A_i$为秩为2的3\*9矩阵；h为1\*9的矩阵，相当于H的一维展开  
$A_i$取行空间的基，即取其中两行组成2\*9矩阵  
由此，线性方程组简化为  
  
$$  
A_i h=  
\begin{bmatrix}  
0^T & -w_i' x_i^T & y_i' x_i^T \\  
w_i' x_i^T & 0^T & -x_i' x_i^T  
\end{bmatrix}  
\begin{pmatrix}  
h^1 \\  
h^2 \\  
h^3  
\end{pmatrix}  
= 0  
$$  
求解h，即H，有8dof，因此需要秩8矩阵，即四个上述方程组，即需要四组x'与x  
  
注：  
$x_i'=Hx_i$实际上应为$\lambda x_i'=Hx_i$，而叉乘后$\lambda x_i' \times Hx_i=0$可以消去这个不确定的尺度因子$\lambda$  
  
#### 超定解  
有n组对应点时，$A_iH$组成2n\*9方程组AH=0  
为在超定情况下取最优解，在约束||H||=1的情况下，使||AH||最小化，即求||AH||/||H||最小化  
最小化2范数||Ah||   
满足此条件的h就是A最小特征值的特征向量  
因此对A进行SVD分解后，$A=UDV^T$，D为正对角矩阵且降序时，V的最后一列就是解h  
  
  
#### k维变换求解通用流程  
- 归一化DLT  
	- 目标：给定 $n > 4$ 组 2D 到 2D 的点对应 $\{\mathbf{x}_i \leftrightarrow \mathbf{x}_i'\}$，确定 2D 单应矩阵 $H$ 使得 $\mathbf{x}_i' = H\mathbf{x}_i$  
	- 算法：  
		- 归一化 $\mathbf{x}$：计算一个只包括位移和缩放的相似变换 $T$，将点 $\mathbf{x}_i$ 变到新的点集 $\bar{\mathbf{x}}_i$，使得点 $\bar{\mathbf{x}}_i$ 的形心位于原点 $(0,0)^T$，并且它们到原点的平均距离是 $\sqrt{2}$  
		- 归一化 $\mathbf{x}'$：针对第二幅图像上的点，类似地计算一个相似变换 $T'$，将点 $\mathbf{x}'_i$ 变换到 $\bar{\mathbf{x}}'_i$  
		- 一组对应实体，点线面等，提供一个秩k方程组$A_i\bar{h}=0$，而对应k维射影变换有$2^{k+1} -1$dof（其他变换同理）  
		- 提供n组一般实体（一般实体的一般性取决于相互能否确定），使得$nk \ge 2^{k+1}-1$，组成方程组$A\bar{h}=0$  
		- 使用不同求超定解方法求解h，转换为$\bar{H}$  
		- 解除归一化：令 $H = T'^{-1} \bar{H} T$  
- 估计单应映射  
	- 目标：给定 $n > 4$ 组图像点对应 $\mathbf{x}_i \leftrightarrow \mathbf{x}_i'$，确定两图像之间单应的最大似然估计 $\hat{H}$。MLE 还包括最小化  
	- 算法：  
		- 初始化：计算一个初始估计 $\hat{H}$ 以提供几何最小化的一个初始点  
		- **几何最小化/Sampson 误差**  
			- 最小化几何误差的 Sampson 近似式$\|\delta_x\|^2 = \delta_x^T \delta_x = \epsilon^T(JJ^T)^{-1}\epsilon$。  
			- 代价函数的最小化可以在 $\hat{H}$ 的适当参数化下采用 Newton 算法 (A6.1 节) 或 Levenberg-Marquardt算法。例如该矩阵可以用它的 9 个元素来参数化  
		- **或用黄金标准误差**  
			- 用测量点 $\mathbf{x}_i$ 或 (最好) 用这些点的 Sampson 校正式$\delta_x = -J^T(JJ^T)^{-1}\epsilon$来计算附属变量 $\hat{\mathbf{x}}_i$ 的初始估计  
			- 在 $\hat{H}$ 和 $i = 1, \cdots, n$ 上最小化代价函数$$\sum_i d(\mathbf{x}_i, \hat{\mathbf{x}}_i)^2 + d(\mathbf{x}_i', \hat{\mathbf{x}}_i')^2$$  
				用 Levenberg-Marquardt 算法在 $2n + 9$ 个变量上最小化代价函数，其中 $2n$ 对应于 $n$ 个 2D 点，而 9 对应于单应矩阵 $\hat{H}$  
			- 点数目过大时，采用 #todo A6.4的稀疏方法最小化  
#### 不同代价函数  
- 代数距离  
	残差向量$\epsilon =Ah$  
	最小化残差向量的范数  
	一组对应点$x_i$和$x_i‘$有一个$\epsilon_i$   
	两点代数距离一般形式：  
  
	$$  
	d_{\text{alg}}(\mathbf{x}_1, \mathbf{x}_2)^2 = a_1^2 + a_2^2 \quad \text{其中} \quad \mathbf{a} = (a_1, a_2, a_3)^T = \mathbf{x}_1 \times \mathbf{x}_2  
	$$  
	两对应点代数距离的特殊形式：  
  
	$$  
	d_{\text{alg}}(\mathbf{x}_i', \mathbf{Hx}_i)^2 = \|\epsilon_i\|^2 =   
	\begin{bmatrix}  
	\mathbf{0}^T & -w_i' \mathbf{x}_i^T & y_i' \mathbf{x}_i^T \\  
	w_i' \mathbf{x}_i^T & \mathbf{0}^T & -x_i' \mathbf{x}_i^T  
	\end{bmatrix} \mathbf{h}  
	$$  
  
	$$  
	\sum_i d_{\text{alg}}(\mathbf{x}_i', \mathbf{Hx}_i)^2 = \sum_i \|\epsilon_i\|^2 = \|\mathbf{A} \mathbf{h}\|^2 = \|\epsilon\|^2  
	$$  
	由此最小化$\epsilon$  
- 几何距离  
	由第一幅图映射到第二幅图  
	$\mathbf{x}$ 表示测量得到的图像坐标点；$\hat{\mathbf{x}}$ 表示点的估计值，而 $\overline{\mathbf{x}}$ 表示点的真值  
	不带’表示第一幅图（原图）的点，带‘表示第二幅图（映射图）的点  
	- 单幅图像误差（最小化转移误差）  
		第一副图几乎准确的情况下  
		x‘为第二幅图的测量结果  
		转移误差为x’与映射结果$H\overline{\mathbf{x}}$的欧氏距离  
		即转移误差的累和为  
  
		$$\sum_i d(\mathbf{x}_i',\mathbf{H}\overline{\mathbf{x}}_i)^2$$  
	- 对称转移误差  
		两幅图都有误差  
		同时考虑前向变换（$\mathbf{H}$）和后向变换（$\mathbf{H}^{-1}$）并把这两种变换对应的几何误差累加  
		即$$\sum_i d(\mathbf{x}_i, \mathbf{H}^{-1}\mathbf{x}_i')^2 + d(\mathbf{x}_i', \mathbf{H}\mathbf{x}_i)^2 $$  
	- 重投影误差  
		当找到一对经$\hat{\mathbf{H}}$完全匹配的点$\hat{\mathbf{x}}$与$\hat{\mathbf{x'}}$ 时，即$\hat{\mathbf{x'}}=\hat{\mathbf{H}}\hat{\mathbf{x}}$，利用这对点可以同时校正第一幅图上的x与第二幅图上的x‘  
		即$$\sum_i d(\mathbf{x}_i,\hat{\mathbf{x}_i})^2 + d(\mathbf{x}_i',\hat{\mathbf{x'}_i})^2 $$  
- 几何距离与代数距离关系  
	$\mathbf{x}_i' = (x_i', y_i', w_i')^T$  
	$\hat{\mathbf{x}}_i'=(\hat{x}_i', \hat{y}_i', \hat{w}_i')^T  = \mathbf{H}\overline{\mathbf{x}}$  
  
	$$  
	d(\mathbf{x}_i', \hat{\mathbf{x}}_i') = d_{\text{alg}} (\mathbf{x}_i', hat{\mathbf{x}}_i') / (\hat{w}_i' w_i')  
	$$  
	可以假定测量值x’的$w_i'=1$  
	仿射变换下，H矩阵最后一个元素为1，使得$\hat{w}_i'=\overline{w}_i'=1$  
	由此，仿射变换下，几何距离等于代数距离，可以将几何距离用于DLT  
- 几何解释  
	- 求单应等价于用一种给定类型的代数族拟合$\mathbb{R}^4$中的一个点集  
		点对 $\mathbf{x}, \mathbf{x}'$ 定义测量空间  的一个点$X$, 其坐标由 $\mathbf{x}, \mathbf{x}'$ 的非齐次坐标拼成  
		一个单应 $H$, 满足 $\mathbf{x}' \times H\mathbf{x} = 0$ 的图像对应 $\mathbf{x} \leftrightarrow \mathbf{x}'$ 定义了 $\mathbb{R}^4$ 中的一个代数族 $\mathcal{V}_H$，它是两个二次超曲面的交集  
		  
		对$\mathbb{R}^4$ 中的点 $X_i = (x_i, y_i, x_i', y_i')^T$，估计单应H即求通过（或几乎通过）点 $X_i$ 的族 $\mathcal{V}_H$  
		令$\hat{X}_i = (\hat{x}_i, \hat{y}_i, \hat{x}_i', \hat{y}_i')^T$ 为在族 $\mathcal{V}_H$ 上最靠近 $X_i$ 的点，有$$\|X_i - \hat{X}_i\|^2 = (x_i - \hat{x}_i)^2 + (y_i - \hat{y}_i)^2 + (x_i' - \hat{x}_i')^2 + (y_i' - \hat{y}_i')^2= d(\mathbf{x}_i, \hat{\mathbf{x}}_i)^2 + d(\mathbf{x}_i', \hat{\mathbf{x}}_i')^2$$  
		即$\mathbb{R}^4$ 中的几何距离等价于在两幅图像中的重投影误差  
	- 另一种几何解释  
		#todo p93  
- Sampson误差  
	估计点 $X$ 的一阶近似  
	给定的单应 $H$，任何在 $V_H$ 上的点 $X = (x, y, x', y')^T$ 满足$A\mathbf{h} = 0$，记为 $C_H(X) = 0$  
	用Taylor 展开式一阶逼近这个代价函数  
  
	$$C_H(\hat{X}) =C_H(X + \delta_x) = C_H(X) + \frac{\partial C_H}{\partial X} \delta_x $$  
	记 $\delta_x = \hat{X} - X$，令$\hat{X}$ 在族 $V_H$ 上，使得 $C_H(\hat{X}) = 0$，有$$C_H(X) + (\partial C_H/\partial X)\delta_x = 0$$  
	记为  
  
	$$J\delta_x = -\epsilon$$  
	$J$ 是偏导数矩阵，$\epsilon$ 是与 $X$ 相关的代价函数 $C_H(X)$  
	  
	此时最小化问题为满足 $J\delta_x = -\epsilon$ 条件下使 $\|\delta_x\|$ 取最小值的向量 $\delta_x$  
	即求条件极值，此处使用拉格朗日乘数法  
	引入拉格朗日乘子向量 $\lambda$并添加因子2，转为最小化$\delta_x^T \delta_x - 2\lambda^T(J\delta_x + \epsilon)$  
	对 $\delta_x$ 求导，令其为0，有  
  
	$$2\delta_x^T - 2\lambda^T J = 0^T$$  
	从而得到 $\delta_x = J^T \lambda$   
	代入约束条件得到  
  
	$$\lambda = -(JJ^T)^{-1}\epsilon$$  
	最后回代得到  
  
	$$\delta_x = -J^T(JJ^T)^{-1}\epsilon$$  
	范数 $\|\delta_x\|^2$ 即为 Sampson 误差  
  
	$$\|\delta_x\|^2 = \delta_x^T \delta_x = \epsilon^T(JJ^T)^{-1}\epsilon$$  
	Sampson 误差的推导假定每点有各向同性（圆）误差分布  
	  
	当 $A(X)\mathbf{h}$ 对X为线性时，一阶近似是精确的，此时Sampson 误差等同于几何误差  
  
  
  
#### 变换不变性和归一化  
当$\mathbf{x}$ 被 $\bar{\mathbf{x}} = T\mathbf{x}$ 替代，$\mathbf{x}'$ 被 $\bar{\mathbf{x}}' = T'\mathbf{x}'$ 替代， $T$ 和 $T'$ 是 $3 \times 3$ 可逆矩阵  
代入等式 $\mathbf{x}' = H\mathbf{x}$，得到 $\bar{\mathbf{x}}' = T'H\mathbf{x} = T'HT^{-1}\bar{\mathbf{x}}$  
由此可以改变由x到x’的路径,$H = T'^{-1}\bar{H}T$  
  
- DLT算法的非不变性  
	DLT算法不是相似不变的，即T、T‘为相似变换时算法结果不具有不变性  
	令 $T'$ 为具有缩放因子 $s$ 的相似变换，$T$ 为任意的射影变换。此外，假设 $H$ 是几何 2D 单应并定义 $\bar{H} = T'H T^{-1}$。那么 $\|\bar{A}\bar{h}\| = s \|A h\|$，其中 $h$ 和 $\bar{h}$ 为 $H$ 和 $\bar{H}$ 的元素组成的向量  
	用代数误差表示，即  
  
	$$d_{\text{alg}}(\bar{\mathbf{x}}_i', \bar{H}\bar{\mathbf{x}}_i) = s d_{\text{alg}}(\mathbf{x}_i', H\mathbf{x}_i)$$  
	  
	”最小化$\sum_i d_{\text{alg}}(\mathbf{x}_i', H\mathbf{x}_i)^2$并满足$\|h\| = 1$“，等价于"最小化$\sum_i d_{\text{alg}}(\bar{\mathbf{x}}_i', \bar{H}\bar{\mathbf{x}}_i)^2$并满足$\|h\| = 1$"，但不等价于"最小化$\sum_i d_{\text{alg}}(\bar{\mathbf{x}}_i', \bar{H}\bar{\mathbf{x}}_i)^2$并满足$\|\bar{h}\| = 1$"  
	因此，在 $H$ 和 $\bar{H}$ 之间不存在给出同样的误差 $\varepsilon$ 并同时满足约束 $\|h\| = \|\bar{h}\| = 1$ 的一一对应，$H$不可以由乘积 $T'^{-1}\bar{H}T$ 恢复  
- 几何误差的不变性  
	$T$ 和 $T'$ 表示 $IP^2$ 中的欧氏变换时，由于欧氏距离在欧式变换下不变，有  
  
	$$d(\widetilde{\mathbf{x}}', \widetilde{H}\widetilde{\mathbf{x}}) = d(T'\mathbf{x}', T'H T^{-1}T\mathbf{x}) = d(T'\mathbf{x}', T'H\mathbf{x}) = d(\mathbf{x}', H\mathbf{x})$$  
	即如果 $H$ 最小化对应集的几何误差，那么 $\widetilde{H}$ 最小化变换后的对应集的几何误差，因此，在欧氏变换下最小化几何误差不变  
	在此基础上，相似变换多一个缩放因子，同理在相似变换下最小化几何误差不变  
- 归一化变换（预条件处理）  
	数据归一化之后，DLT就可以关于相似变换不变  
	- 各向同性缩放  
		1.对点进行平移使其形心位于原点  
		2.对点进行缩放使它们到原点的平均距离等于$\sqrt{2}$  
		3.对两幅图像独立进行上述变换  
	- 非各向同性缩放  
		1.对点进行平移使其形心位于原点  
		2.进行坐标尺度缩放使该点集的两主矩都 等于 1. 这样使该点集形成以原点为中心,半径为 1的近似的对称圆云  
		3.对两幅图像独立进行上述变换  
	- 无穷远附近点缩放  
		#todo   
  
  
  
## 统计代价函数与最大似然(ML)估计  
假定图像测量误差遵循零平均各向同性高斯分布，即假定每一幅图像坐标都具有零均值和均匀标准方差 $\sigma$ 的高斯噪声  
有$\mathbf{x} = \overline{\mathbf{x}} + \Delta \mathbf{x}$, 其中 $\Delta \mathbf{x}$ 服从方差 $\sigma^2$ 的高斯分布  
进一步假设每次测量的噪声是相互独立的  
记真值为$\overline{\mathbf{x}}$, 则每个测量点 $\mathbf{x}$ 的概率密度函数PDF是  
  
$$Pr(\mathbf{x}) = \left( \frac{1}{2\pi\sigma^2} \right) e^{-d(\mathbf{x},\overline{\mathbf{x}})^2/(2\sigma^2)}$$  
表示一个被噪声污染的测量点x，在其真实位置 $\overline{\mathbf{x}}$ 附近出现的概率大小  
- 单图像误差  
	每点噪声独立分布，所以获得点对应集 $\{\overline{\mathbf{x}}_i \leftrightarrow \mathbf{x}_i'\}$ 的概率就是它们单个 PDF 的乘积，由此受噪声干扰的数据的PDF是  
  
	$$\Pr(\{\mathbf{x}_i'\} | H) = \prod_i \left( \frac{1}{2\pi\sigma^2} \right) e^{-d(\mathbf{x}_i',H\overline{\mathbf{x}}_i)^2/(2\sigma^2)}$$  
	$\Pr(\{\mathbf{x}_i'\} | H)$ 表示给定真实单应 $H$ 时获得测量 $\{\mathbf{x}_i'\}$ 的概率  
	对数似然为  
  
	$$\log \Pr(\{\mathbf{x}_i'\} | H) = -\frac{1}{2\sigma^2} \sum_i d(\mathbf{x}_i',H\overline{\mathbf{x}}_i)^2 + \text{常数}$$  
	单应的最大似然 (ML) 估计量最大化这个对数似然，即最小化$\sum_i d(\mathbf{x}_i',H\overline{\mathbf{x}}_i)^2$  
	此时ML 估计等价于最小化几何误差函数式  
- 双图像误差  
	对应集真值是 $\{\overline{\mathbf{x}}_i \leftrightarrow H\overline{\mathbf{x}}_i = \overline{\mathbf{x}}_i'\}$，则同理受噪声干扰的数据的PDF是  
  
	$$Pr(\{\mathbf{x}_i, \mathbf{x}_i'\} | H, \{\overline{\mathbf{x}}_i\}) = \prod_{i=1}^n \left( \frac{1}{2\pi\sigma^2} \right) e^{-(d(\mathbf{x}_i, \overline{\mathbf{x}}_i)^2 + d(\mathbf{x}_i', H\overline{\mathbf{x}}_i)^2)/(2\sigma^2)}$$  
	射影变换 $H$ 和对应 $\{\hat{\mathbf{x}}_i \leftrightarrow \hat{\mathbf{x}}_i'\}$ 的 ML 估计是求最小化  
  
	$$  
	\sum_i d(\mathbf{x}_i, \hat{\mathbf{x}}_i)^2 + d(\mathbf{x}_i', \hat{\mathbf{x}}_i')^2  
	$$  
	的单应 $\hat{H}$ 和校正对应 $\{\hat{\mathbf{x}}_i \leftrightarrow \hat{\mathbf{x}}_i'\}$ 且 $\hat{\mathbf{x}}_i' = \hat{H}\hat{\mathbf{x}}_i$  
	此时ML 估计等价于最小化重投影误差函数式  
- Mahalanobis 距离  
	在一般高斯分布的情形，可以假定测量向量 $\mathbf{X}$ 满足一个具有协方差矩阵 $\Sigma$ 的高斯分布函数。上面的情况等价于协方差矩阵是单位矩阵的倍数。  
	最大化对数似然则等价于最小化 Mahalanobis 距离  
  
	$$  
	\| \mathbf{X} - \overline{\mathbf{X}} \|_{\Sigma}^2 = (\mathbf{X} - \overline{\mathbf{X}})^T \Sigma^{-1} (\mathbf{X} - \overline{\mathbf{X}})  
	$$  
	当每幅图像都有误差并假定一幅图像中的误差与另一幅图像中的误差是独立的时，合适的代价函数是  
  
	$$  
	\| \mathbf{X} - \overline{\mathbf{X}} \|_{\Sigma}^2 + \| \mathbf{X}' - \overline{\mathbf{X}}' \|_{\Sigma'}^2  
	$$  
	式中，$\Sigma$ 和 $\Sigma'$ 是两幅图像的测量的协方差矩阵。  
	最后，如果我们假定所有点 $\mathbf{x}_i$ 和 $\mathbf{x}_i'$ 的误差是独立的，并分别具有协方差矩阵 $\Sigma_i$ 和 $\Sigma_i'$，那么上面的表达式展开为  
  
	$$  
	\sum_i \| \mathbf{x}_i - \overline{\mathbf{x}}_i \|_{\Sigma_i}^2 + \sum_i \| \mathbf{x}_i' - \overline{\mathbf{x}}_i' \|_{\Sigma_i'}^2  
	$$  
	这个方程允许用于非各向同性的协方差矩阵，在用两非垂直线的相交来计算点的位置时会出现这种情况。在已知一幅图像中的点是精确的而误差仅发生在另一幅图像时，上式中的两个累加项中的一项消失。  
	#todo 理解此处 P95  
  
  
  
## 迭代最小化方法  
迭代最小化技术一般由五步组成：  
（1）代价函数  
（2）参数化 把要计算的变换（或其他实体）表示成有限数目的参数。一般并不要求它是最小参数集，事实上超参数化常有优越性  
（3）函数确定 必须确定一个用参数集描述的代价函数。  
（4）初始化 计算一个适当的初始参数估计。一般将由一个线性算法（例如DLT算法）来实现。  
（5）迭代 由初始解开始，在迭代中逐步修正参数以达到最小化代价函数的目的。  
  
- 函数确定  
	(1) 有一个协方差矩阵为 $\Sigma$ 的测量向量 $X \in \mathbb{R}^N$。  
	(2) 一组参数被表达成一个向量 $P \in \mathbb{R}^M$。  
	(3) 定义一个映射 $f: \mathbb{R}^M \to \mathbb{R}^N$。此映射的值域 (至少局部地) 是 $\mathbb{R}^N$ 中表示容许测量集的模型曲面 $S$。  
	(4) 要最小化的代价函数是 Mahalanobis 距离的平方  
  
	$$\| X - f(P) \|_{\Sigma}^2 = (X - f(P))^T \Sigma^{-1} (X - f(P))$$  
	此时希望寻找一组参数 $P$ 使 $f(P) = X$, 或 (不成功时) 使 $f(P)$ 在 Mahalanobis 距离意义下尽可能接近 $X$。当最小化代价函数属于此类型时, Levenberg-Marquardt 算法是最小化迭代的一般工具  
	- 单图像误差规范函数  
		固定第一幅图像中的点 $\mathbf{x}_i$，变化 $H$ 以最小化代价函数式$\sum_i d(\mathbf{x}_i', H\overline{\mathbf{x}}_i)^2$  
		测量向量 $X$ 由点 $\mathbf{x}_i'$ 的 $2n$ 个非齐次坐标组成，以单应矩阵 $H$ 的元素组成的向量 $\mathbf{h}$ 作为参数  
		函数f定义为$f: \mathbf{h} \mapsto (H\mathbf{x}_1, H\mathbf{x}_2, \cdots, H\mathbf{x}_n)$  
		此时$\| X - f(\mathbf{h}) \|^2=\sum_i d(\mathbf{x}_i', H\overline{\mathbf{x}}_i)^2$  
	- 对称传递误差规范函数  
		最小化对称代价函数$\sum_i d(\mathbf{x}_i, H^{-1}\mathbf{x}_i')^2 + d(\mathbf{x}_i', H\mathbf{x}_i)^2$  
		测量向量 $X$ 为由点 $\mathbf{x}_i$ 和 $\mathbf{x}_i'$ 的非齐次坐标组成的 $4n$ 维向量，参数向量是由 $H$ 的元素组成的向量 $\mathbf{h}$  
		函数为$f: \mathbf{h} \mapsto (H^{-1}\mathbf{x}_1', \cdots, H^{-1}\mathbf{x}_n', H\mathbf{x}_1, \cdots, H\mathbf{x}_n)$  
		此时$\| X - f(\mathbf{h}) \|^2=\sum_i d(\mathbf{x}_i, H^{-1}\mathbf{x}_i')^2 + d(\mathbf{x}_i', H\mathbf{x}_i)^2$  
	- 重投影误差规范函数  
		测量向量$X$由点 $\hat{\mathbf{x}}_i$ 坐标和 $\hat{H}$ 矩阵的元素总共 $2n+9$ 个参数组成，对 $\hat{\mathbf{x}}_i'$ 的坐标可不做要求  
		参数向量是 $P = (\mathbf{h}, \hat{\mathbf{x}}_1, \cdots, \hat{\mathbf{x}}_n)$  
		函数为$f: (\mathbf{h}, \hat{\mathbf{x}}_1, \cdots, \hat{\mathbf{x}}_n) \mapsto (\hat{\mathbf{x}}_1, \hat{\mathbf{x}}_1', \cdots, \hat{\mathbf{x}}_n, \hat{\mathbf{x}}_n')$  
		式中，$\hat{\mathbf{x}}_i' = \hat{H} \hat{\mathbf{x}}_i$  
		此时$\| X - f(P) \|^2=\sum_i d(\mathbf{x}_i,\hat{\mathbf{x}_i})^2 + d(\mathbf{x}_i',\hat{\mathbf{x'}_i})^2$  
	- Sampson近似  
		#todo p102   
- 初始化  
	- 从参数空间一个已知固定点开始  
	- 根据某种方式在参数空间大量采样分别迭代  
	- 线性技术：利用归一化DLT求一个H  
	- 最小配置解：仅选4组对应求9维的h  
- 迭代方法  
	Newton/Levenberg-Marquardt  
  
  
## 鲁棒估计  
野值：错配点  
  
#### 随机抽样一致算法 RANSAC  
**作用是取得较优初始解，避免局部最优**  
通过随机取两点来随机取直线  
根据直线支集（距离小于阈值的点的数量）大小度量拟合效果，最大的直线为**鲁棒拟合**  
  
随机样本：包含足以确定模型的最小数据集~两点  
模型：用于拟合数据的对象~直线  
  
  
- 算法（参数：t，T，N）：  
	- 目的：拟合含野值的数据集S的一个模型  
	- 实现：  
		- 选数据点取样本  
		- 根据距离阈值t计算内点数，同时计算出一致集$S_i$  
		- 根据数量阈值T衡量模型，达标（大于T）则利用一致集重估计模型  
		- 否则重复至多N次，取最大一致集$S_i$重估计模型  
- 距离阈值t （参数：$\alpha$）  
	t决定$\alpha$（点为内点的概率）  
	一般取$\alpha=95\%$，然后根据下式计算所需的t  
  
	$$F_m(k^2) = \int_0^{k^2} \chi_m^2(\xi) d\xi  \ \ \ m为余维度$$  
  
	$$t^2 = F_m^{-1}(\alpha) \sigma^2$$  
	距离d小于t为内点，大于等于t为野值  
	- 余维度：确定模型最小数据集的数据数量  
		1：直线/基本矩阵  
		2：单应矩阵  
		3：三焦点张量  
- 取样次数N （参数：s，p，$\epsilon$）  
	随机样本点数为s时，N次中至少一次无野值概率为p  
	$P(任取一点野值)=\epsilon$  
	则$$N=\frac{\log(1-p)}{\log\left(1-(1-\epsilon)^s\right)}$$  
- 数量阈值T（参数：$\epsilon$）  
	数据集S共n个点时，一致集$S_i$大小趋于内点数量即可  
	即  
  
	$$T=(1-\epsilon)n$$  
上述参数中，$\epsilon$值初始未知，通常从大值（最坏情况）开始尝试，根据采样一致集最大值降低$\epsilon$  
其余值可以人为指定/自适应更新  
据此更新N并确定迭代终点（更新的N小于已采样次数）  
  
#### 最小中值平方LMS  
作用同RANSAC  
根据所有点距离中值，选最小中值模型  
不需要阈值、误差方差等先验值  
野值大于一半时失效  
  
#### 鲁棒最大似然估计  
用于在RANSAC最后拟合模型  
取鲁棒代价函数为  
  
$$  
D = \sum_i \gamma(d_i) \quad \text{且} \quad \gamma(e) =   
\begin{cases}   
e^{2} & e^{2} < t^{2} \\  
t^{2} & e^{2} \geq t^{2}  
\end{cases}  
$$  
阈值$t^2$同上由卡方定义。该函数可以考虑所有点而不只是内点  
反复相互更新”估计结果模型“与”内点数“，迭代至内点数收敛  
  
  
  
## 单应自动计算  
- 目的  
	计算两幅图像间的 2D 单应  
- 算法  
	- 兴趣点：在每一幅图像上计算兴趣点  
	- 假设对应：根据兴趣点灰度邻域的接近和相似，计算它们的匹配集  
	- RANSAC 鲁棒估计：重复 $N$ 次采样，这里 $N$ 用RANSAC中的自适应方法确定  
		- 选择由四组对应组成的一个随机样本并计算单应 $H$  
		- 对假设的每组对应，计算距离 $d_{\perp}$  
		- 根据 $d_{\perp} < \sqrt{5.99\sigma}$ 像素确定对应数，进而计算与 $H$ 一致的内点数  
		选择具有最大内点数的 $H$。在数目相等时选择内点的标准方差最低的 $H$  
	- 最优估计：由划定为内点的所有对应重新估计 $H$，用 Levenberg-Marquardt 算法来最小化 ML 代价函数式（重投影误差）  
	- 引导匹配：用估计的 $H$ 去定义转移点位置附近的搜索区域，进一步确定兴趣点的对应。最后两步可以重复直到对应的数目稳定为止  
  
  
- 兴趣点：通过自相关函数最小值确定，注意样本与兴趣点在图像的分布均匀  
  
- 对应：  
	通过互相关函数SSD（灰度差平方和）/CC在两幅图像的兴趣点之间相互取匹配最高者，实现一一对应  
	可以通过限制运动范围（视差）等方式减小匹配难度  
  
- 距离：估计单应时的“距离”可以用几种多图像误差函数  
  
  
  
  
#todo 章节末附录阅读p113  